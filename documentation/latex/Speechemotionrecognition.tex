%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,polish]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
 \ifdefined\DeclareUnicodeCharacterAsOptional
  \DeclareUnicodeCharacter{"00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{"2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{"2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{"2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{"251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{"2572}{\textbackslash}
 \else
  \DeclareUnicodeCharacter{00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{2572}{\textbackslash}
 \fi
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Sonny]{fncychap}
\usepackage[dontkeepoldnames]{sphinx}

\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}
\addto\captionspolish{\renewcommand{\contentsname}{Contents:}}

\addto\captionspolish{\renewcommand{\figurename}{Rys.}}
\addto\captionspolish{\renewcommand{\tablename}{Tabela}}
\addto\captionspolish{\renewcommand{\literalblockname}{Listing}}

\addto\captionspolish{\renewcommand{\literalblockcontinuedname}{kontynuacja poprzedniej strony}}
\addto\captionspolish{\renewcommand{\literalblockcontinuesname}{continues on next page}}

\addto\extraspolish{\def\pageautorefname{strona}}

\setcounter{tocdepth}{1}



\title{Speech emotion recognition Documentation}
\date{15 sty 2018}
\release{1.0}
\author{Elżbieta Plaszczyk}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Wydanie}
\makeindex

\begin{document}
\ifnum\catcode`\"=\active\shorthandoff{"}\fi
\maketitle
\sphinxtableofcontents
\phantomsection\label{\detokenize{index::doc}}



\chapter{speech\_emotion\_recognition}
\label{\detokenize{modules::doc}}\label{\detokenize{modules:speech-emotion-recognition}}\label{\detokenize{modules:welcome-to-y-s-documentation}}

\section{HMM module}
\label{\detokenize{HMM:hmm-module}}\label{\detokenize{HMM::doc}}\label{\detokenize{HMM:module-HMM}}\index{HMM (moduł)}\index{HMM (klasa w module HMM)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{HMM:HMM.HMM}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{HMM.}\sphinxbfcode{HMM}}{\emph{transition\_ppb}, \emph{states\_num}, \emph{observations}}{}
Klasy bazowe: \sphinxcode{object}

Klasa implementująca algorytm Ukryte Modle Markova dla problemu rozpoznawania emocji z głosu.

Dany jest zbiór uczący zawieracjący obserwację (wektory cech), z któżych każda ma przypisaną emocję jaką dany wektor
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{hidden\_states\_num} (\sphinxstyleliteralemphasis{int}) \textendash{} liczba ukrytych modeli Markowa

\item {} 
\sphinxstyleliteralstrong{observations\_num} (\sphinxstyleliteralemphasis{int}) \textendash{} liczba wszystkich możliwych obserwacji

\item {} 
\sphinxstyleliteralstrong{observation\_dict} (\sphinxstyleliteralemphasis{dict}) \textendash{} słownik zawierający dla każdej obserawacji jej index w tablicy emission\_ppb

\item {} 
\sphinxstyleliteralstrong{emission\_ppb} (\sphinxstyleliteralemphasis{matrix}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{hidden\_states\_num}\sphinxstyleliteralemphasis{{]}}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{observations\_num}\sphinxstyleliteralemphasis{{]}}) \textendash{} tablica zawierająca dla każdego stanu S
i każdej obserawcji O prawdopodobieństwo wygenerowanie B w stanie O

\item {} 
\sphinxstyleliteralstrong{transition\_ppb} (\sphinxstyleliteralemphasis{matrix}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{hidden\_states\_num}\sphinxstyleliteralemphasis{{]}}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{hidden\_states\_num}\sphinxstyleliteralemphasis{{]}}) \textendash{} tablica prawdopodobieństw przejść pomiedzy
stanami. matrix{[}i{]}{[}j{]} - prawdopodobieństwo przejśćia z stanu i do stanu j

\item {} 
\sphinxstyleliteralstrong{initial\_ppb} (\sphinxstyleliteralemphasis{list}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{hidden\_states\_num}\sphinxstyleliteralemphasis{{]}}) \textendash{} lista prawdopodobieństw przejsć z stanu początkowego dostanu każdego
z ukrytych stanów.

\end{itemize}

\end{description}\end{quote}
\index{\_\_init\_\_() (HMM.HMM metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{HMM:HMM.HMM.__init__}}\pysiglinewithargsret{\sphinxbfcode{\_\_init\_\_}}{\emph{transition\_ppb}, \emph{states\_num}, \emph{observations}}{}
Konstruktor klasy HMM.

Tworzy tablicę przejść pomiędzy stanami, transition\_ppb.
Dla dowolnych 2 stanów s\_i i s\_j, prawdopodobnieństwo przejścia z stanu s\_i do stanu s\_j: p(s\_i, s\_j) jest równe:
\begin{itemize}
\item {} 
transition\_ppb{[}i{]}{[}0{]} jeżeli i == j

\item {} 
transition\_ppb{[}i{]}{[}1{]} jeżeli i == j-1

\item {} 
0 w przeciwnym przypadku

\end{itemize}

Tworzy tablicę emisji: emission\_ppb. Na początku dla każdego stanu S i każdej obserwacji O prawdopodobieństwo
przejścia emisji O w stanie S jest równe.

Tworzy tablicę: initial\_ppb. Na początku dla każdego stanu S prawdopodobieństwo przejścia ze stanu początkowego
do stanu S jest równe.
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{transition\_ppb} (\sphinxstyleliteralemphasis{matrix}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{states\_num}\sphinxstyleliteralemphasis{{]}}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{2}\sphinxstyleliteralemphasis{{]}}) \textendash{} 
macierz prawdopodobieństw przejść pomiędzy stanami.
\begin{itemize}
\item {} 
matrix{[}i{]}{[}0{]} - zawiera pradopodobieńśwo przejśćia z stanu i do stanu i,

\item {} 
matrix{[}i{]}{[}1{]} - zawiera pradopodobieńśwo przejśćia z stanu i do stanu (i+1)

\end{itemize}


\item {} 
\sphinxstyleliteralstrong{states\_num} (\sphinxstyleliteralemphasis{int}) \textendash{} liczba ukrytych stanow

\item {} 
\sphinxstyleliteralstrong{observations} (\sphinxstyleliteralemphasis{list}) \textendash{} lista wszystkich możliwych obserwacji

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{backward\_algorithm() (HMM.HMM metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{HMM:HMM.HMM.backward_algorithm}}\pysiglinewithargsret{\sphinxbfcode{backward\_algorithm}}{\emph{ob\_sequence}}{}
Implementacja algorytmu sufiksowego (backward algorithm)
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode
\sphinxstyleliteralstrong{ob\_sequence} (\sphinxstyleliteralemphasis{list}) \textendash{} sekwencja obserwacji

\end{description}\end{quote}

:return matrix{[}hidden\_states\_num{]}{[}len(observation\_seq){]}, matrix{[}i{]}{[}t{]}
\begin{quote}

Opis algorytmu:
\end{quote}

Dane:
Y = {[}y\_0, y\_1, … , y\_n{]} - observation\_seq
X = {[}x\_1, x\_1, … , x\_k{]} - ukryte stany markowa
\begin{quote}

Cel:
\end{quote}

macierz beta{[}{[}hidden\_states\_num{]}{[}n{]}) taka, że:
beta{[}i{]}{[}t{]} = P(Y{[}t+1{]} = y\_t+1, Y{[}t+1{]} = y\_t+1, …, Y{[}n{]} = y\_n \textbar{} X\_t = i) - prawdopodobienstwo
zaobserwowania obserwacji y(t+1:n) zaczynając w punkcie i w czasie t.
\begin{quote}

Algorytm:
\end{quote}
\begin{itemize}
\item {} 
beta{[}i{]}{[}n{]} = 1

\item {} 
beta{[}i{]}{[}t{]} = {[}sum\_\{j=1\}\textasciicircum{}\{k\} (emission\_ppb{[}j{]}{[}y\_t+1{]} * beta{[}j{]}{[}t+1{]} * transition\_ppb{[}i{]}{[}j{]}{]}

\end{itemize}

\end{fulllineitems}

\index{baum\_welch\_algorithm() (HMM.HMM metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{HMM:HMM.HMM.baum_welch_algorithm}}\pysiglinewithargsret{\sphinxbfcode{baum\_welch\_algorithm}}{\emph{observations}, \emph{observations\_num}, \emph{obs\_seq\_len}, \emph{laplance\_smoothing=0.001}}{}
Implementacja algorytmu bauma-welcha z użyciem równania Levinsona, dla N niezależnych sekwencji obserwacji.
Algorytm służy to reestymacji parametrów ukrytych modeli Markowa
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{observations} (\sphinxstyleliteralemphasis{list}) \textendash{} lista sekwencji obserwacji

\item {} 
\sphinxstyleliteralstrong{observations\_num} (\sphinxstyleliteralemphasis{int}) \textendash{} liczba sekwencji obserwacji

\item {} 
\sphinxstyleliteralstrong{obs\_seq\_len} (\sphinxstyleliteralemphasis{int}) \textendash{} długość każdej z sekwencji obserwacji

\item {} 
\sphinxstyleliteralstrong{laplance\_smoothing} \textendash{} minimalne pradopodobieństwo wyrzucenia obserwacji

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{create\_emission\_ppb() (HMM.HMM metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{HMM:HMM.HMM.create_emission_ppb}}\pysiglinewithargsret{\sphinxbfcode{create\_emission\_ppb}}{}{}
Funckcja dla każdej obseracji i każdego stanu tworzy tablicę prawodopodobieństw wyrzucenia obserwacji w
danym stanie
\begin{quote}\begin{description}
\item[{Return matrix{[}state\_num{]}{[}observation\_num{]}}] \leavevmode
macierz emisji prawdopodobieństw obserwacji

\end{description}\end{quote}

\end{fulllineitems}

\index{create\_initial\_ppb() (HMM.HMM metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{HMM:HMM.HMM.create_initial_ppb}}\pysiglinewithargsret{\sphinxbfcode{create\_initial\_ppb}}{\emph{states\_num}}{}
Funkcja tworzy wektor prawdopodobieństw przejść ze stanu początkowe do każdego z ukrytych stanów

:return list{[}states\_num{]}

\end{fulllineitems}

\index{create\_observation\_dict() (HMM.HMM metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{HMM:HMM.HMM.create_observation_dict}}\pysiglinewithargsret{\sphinxbfcode{create\_observation\_dict}}{\emph{observations}}{}
Funkcja tworzy słownik obserwacji. Każdą obserwacje zamienia na string i przypisuje unikatowy
numer z przedziału {[}0, len(observations)-1{]}.
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode
\sphinxstyleliteralstrong{observations} (\sphinxstyleliteralemphasis{list}) \textendash{} lista obserwacji (wektorów cech)

\end{description}\end{quote}

:return słownik obserwacji

\end{fulllineitems}

\index{create\_transition\_ppb() (HMM.HMM metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{HMM:HMM.HMM.create_transition_ppb}}\pysiglinewithargsret{\sphinxbfcode{create\_transition\_ppb}}{\emph{states\_num}, \emph{given\_transition\_ppb}}{}~\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{states\_num} (\sphinxstyleliteralemphasis{int}) \textendash{} liczba stanów

\item {} 
\sphinxstyleliteralstrong{given\_transition\_ppb} (\sphinxstyleliteralemphasis{matrix}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{state\_num}\sphinxstyleliteralemphasis{{]}}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{2}\sphinxstyleliteralemphasis{{]}}) \textendash{} tablica prawdopodobieństw przejść pomiedzy kolejnymi stanami

\end{itemize}

\item[{Return matrix{[}states\_num{]}{[}states\_num{]}}] \leavevmode
macierz prawdopodobieństw przejść pomiędzy stanami

\end{description}\end{quote}

\end{fulllineitems}

\index{evaluate() (HMM.HMM metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{HMM:HMM.HMM.evaluate}}\pysiglinewithargsret{\sphinxbfcode{evaluate}}{\emph{obs\_sequence}}{}
Funckcja oblicza prawdopodobieństwo, że dana sekwencja obserwacji została wyprodukowana przez ten model.
\begin{quote}\begin{description}
\item[{Param}] \leavevmode
list obs\_sequence: lista obserwacji

\end{description}\end{quote}

\end{fulllineitems}

\index{forward\_algorithm() (HMM.HMM metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{HMM:HMM.HMM.forward_algorithm}}\pysiglinewithargsret{\sphinxbfcode{forward\_algorithm}}{\emph{observation\_seq}}{}
Implementacja algorytmu prefiksowego (forward algorithm).
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode
\sphinxstyleliteralstrong{observation\_seq} (\sphinxstyleliteralemphasis{list}) \textendash{} sekwencja obserwacji

\end{description}\end{quote}

:return matrix{[}hidden\_states\_num{]}{[}len(observation\_seq){]}, matrix{[}i{]}{[}t{]}

Opis algorytmu:
Dane:
Y = {[}y\_0, y\_1, … , y\_n{]} - observation\_seq
X = {[}x\_1, x\_1, … , x\_k{]} - ukryte stany markowa

Cel:
macierz alfa{[}{[}hidden\_states\_num{]}{[}n{]}) taka, że:
\begin{quote}
\begin{description}
\item[{alfa{[}i{]}{[}t{]} = P(Y{[}0{]} = y\_0, Y{[}1{]} = y\_1, …, Y{[}t{]} = y\_t \textbar{} X\_t = i) - prawdopodobienstwo wygenerowania}] \leavevmode
y(0:t) przy założeniu, że w czasie t byliśmy w stanie i.

\end{description}
\end{quote}

Algorytm:
\begin{itemize}
\item {} 
alfa{[}i{]}{[}0{]} = initial\_ppb{[}i{]} * emission\_ppb{[}i{]}{[}y\_0{]}

\item {} 
alfa{[}j{]}{[}t{]} = {[}sum\_\{i=1\}\textasciicircum{}\{k\} (alfa{[}i{]}{[}t-1{]})*transition\_ppb{[}i{]}{[}j{]}{]} * emission\_ppb{[}j{]}{[}y\_t{]}

\end{itemize}

\end{fulllineitems}

\index{get\_parameters() (HMM.HMM metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{HMM:HMM.HMM.get_parameters}}\pysiglinewithargsret{\sphinxbfcode{get\_parameters}}{}{}
Funkcja zwraca parametry obiektu
\begin{description}
\item[{:return}] \leavevmode\begin{itemize}
\item {} 
transiton\_ppb

\item {} 
emission\_ppb

\item {} 
initial\_ppb

\item {} 
observation\_dict

\end{itemize}

\end{description}

\end{fulllineitems}

\index{learn() (HMM.HMM metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{HMM:HMM.HMM.learn}}\pysiglinewithargsret{\sphinxbfcode{learn}}{\emph{training\_set}, \emph{laplance\_smoothing=0.001}}{}
Funkcja trenuje model HMM za pomocą podanego zbioru uczącego
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{training\_set} (\sphinxstyleliteralemphasis{list}) \textendash{} zbiór uczący postaci lista seqwencji obserwacji.

\item {} 
\sphinxstyleliteralstrong{laplance\_smoothing} (\sphinxstyleliteralemphasis{float}) \textendash{} minimalne prawdopodobieństwo wygenerowania obserwacji przez dany model

\end{itemize}

\end{description}\end{quote}

Ponieważ obserwacje modelu są typu string, najpierw zamienia każdą obserwację na elementy typu string.
Następnie powtarza algorytm Bauma-Welcha na zbiorze uczącym, określoną ilość razy, lub dopóki różnica
prawdopodobieństw wygenerowania zbioru uczącego w starym modelu i nowym będzie mniejsze niż epsilon.

\end{fulllineitems}

\index{print\_params() (HMM.HMM metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{HMM:HMM.HMM.print_params}}\pysiglinewithargsret{\sphinxbfcode{print\_params}}{}{}
Funkcja wypisuje parametry modelu HMM

\end{fulllineitems}


\end{fulllineitems}



\section{KNN module}
\label{\detokenize{KNN:module-KNN}}\label{\detokenize{KNN::doc}}\label{\detokenize{KNN:knn-module}}\index{KNN (moduł)}\index{KNN (klasa w module KNN)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{KNN:KNN.KNN}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{KNN.}\sphinxbfcode{KNN}}{\emph{train\_set}}{}
Klasy bazowe: \sphinxcode{object}

Klasa implementująca algorytm K najbliższych sąsiadów dla problemu rozpoznawania emocji z głosu

Dany jest zbiór uczący zawieracjący obserwację (wektory cech), z któżych każda ma przypisaną emocję jaką dany wektor
reprezentuje. Zbiór uczący zostaje znormalizowany a zmienne użyte do normalizacje zapisane jako parametry obiektu.
\begin{description}
\item[{Dany jest zbiór obserwacji C = (c\_1, c\_2 … c\_k\}. Celem jest na podstawie informacji z zbioru uczącego}] \leavevmode
przewidzenie jaką emocję reprezentuje dany zbiór obserwacji.

\end{description}

S = {[}{]} - zbiór stanów wynikowych

Algorytm predycji:
Dla każdej obserwacji c\_i :
\begin{itemize}
\item {} 
c\_i zostaje znormalizowane wartościami którymi znormalizowany został zbiór uczący.

\item {} 
Obliczana jest odległość euklidesowa pomiedczy c\_i a każdym wektorem z zbioru uczącego

\item {} 
Z zbioru uczącego wybierane jest k wektorów, których odległość do c\_i jest najmniejsza.

\item {} 
Sumowane są stany które reprezentują zbiór k wektorów.

\item {} 
Stany które wystąpiły najczęściej dodawane są do S

\end{itemize}

Stany które wystąpiły najczęściej w S są zwracane jako możliwe stany reprezentujace dany zbiór obserwacji
\index{\_\_init\_\_() (KNN.KNN metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{KNN:KNN.KNN.__init__}}\pysiglinewithargsret{\sphinxbfcode{\_\_init\_\_}}{\emph{train\_set}}{}
Konstruktor klasy.
Normalizuje i zapisuje zbiór uczący
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode
\sphinxstyleliteralstrong{train\_set} (\sphinxstyleliteralemphasis{list}) \textendash{} zbiór uczący dany model KNN -\textgreater{} lista wektorów postaci
{[}wektor\_cech, emocja jaką reprezentuje{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{compute\_emotion() (KNN.KNN metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{KNN:KNN.KNN.compute_emotion}}\pysiglinewithargsret{\sphinxbfcode{compute\_emotion}}{\emph{obs\_sequence}, \emph{num\_of\_nearest\_neighbour}}{}
Funkcja dla każdego wektora z zbioru obserwacji, zlicza prawdopodobne stany jakie reprezentują.
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{obs\_sequence} (\sphinxstyleliteralemphasis{list}) \textendash{} lista obserwacji (wektorów) reprezentujących wypowiedź, której stan emocjonalny trzeba
rozpoznać

\item {} 
\sphinxstyleliteralstrong{num\_num\_of\_nearest\_neighbour} (\sphinxstyleliteralemphasis{int}) \textendash{} liczba najbliższych sąsiadów.

\end{itemize}

\end{description}\end{quote}

:return stany najczęściej występujące w podanej sekwencji obserwacji.

\end{fulllineitems}

\index{get\_emotion() (KNN.KNN metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{KNN:KNN.KNN.get_emotion}}\pysiglinewithargsret{\sphinxbfcode{get\_emotion}}{\emph{test\_vector}, \emph{num\_of\_nearest\_neighbour}}{}
Funkcja porównuje podany wektor emocji z każdym z zbioru trenującego i wybiera k najbliższych.
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{test\_vector} (\sphinxstyleliteralemphasis{vector}) \textendash{} wektor, którego stan należy odgadnąć

\item {} 
\sphinxstyleliteralstrong{num\_num\_of\_nearest\_neighbour} (\sphinxstyleliteralemphasis{int}) \textendash{} liczba najbliższych sąsiadów, z których należy wziąć stan do porównania.

\end{itemize}

\end{description}\end{quote}

:return lista stanów których wektory pojawiły sie najczęściej w grupie k najbliższych wektorów.

\end{fulllineitems}

\index{normalize() (KNN.KNN metoda statyczna)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{KNN:KNN.KNN.normalize}}\pysiglinewithargsret{\sphinxbfcode{static }\sphinxbfcode{normalize}}{\emph{feature\_vector\_set}}{}
Normalizuje zbiór listę wektórów postaci {[}wektor\_cecg, emocja{]}
\begin{quote}\begin{description}
\item[{Param}] \leavevmode
feature\_vector\_set: Zbiór wektorów cech do znormalizowania

\item[{Zwraca}] \leavevmode
\begin{itemize}
\item {} 
wektor najmniejszych wartości z każdej cechy

\item {} 
wektor największych wartości z każdej cechy

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\section{hanning\_window module}
\label{\detokenize{hanning_window:module-hanning_window}}\label{\detokenize{hanning_window:hanning-window-module}}\label{\detokenize{hanning_window::doc}}\index{hanning\_window (moduł)}\index{HanningWindow (klasa w module hanning\_window)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{hanning_window:hanning_window.HanningWindow}}\pysiglinewithargsret{\sphinxbfcode{class }\sphinxcode{hanning\_window.}\sphinxbfcode{HanningWindow}}{\emph{size}}{}
Klasy bazowe: \sphinxcode{object}
\index{\_\_init\_\_() (hanning\_window.HanningWindow metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{hanning_window:hanning_window.HanningWindow.__init__}}\pysiglinewithargsret{\sphinxbfcode{\_\_init\_\_}}{\emph{size}}{}
\end{fulllineitems}

\index{plot() (hanning\_window.HanningWindow metoda)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{hanning_window:hanning_window.HanningWindow.plot}}\pysiglinewithargsret{\sphinxbfcode{plot}}{\emph{signal}}{}
\end{fulllineitems}


\end{fulllineitems}



\section{helper\_file module}
\label{\detokenize{helper_file::doc}}\label{\detokenize{helper_file:module-helper_file}}\label{\detokenize{helper_file:helper-file-module}}\index{helper\_file (moduł)}\index{build\_file\_set() (w module helper\_file)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{helper_file:helper_file.build_file_set}}\pysiglinewithargsret{\sphinxcode{helper\_file.}\sphinxbfcode{build\_file\_set}}{\emph{path\_pattern}}{}~\begin{description}
\item[{Funkcja tworzy listę plików znajdujących sie w katalogu path\_pattern z rozszerzeniem wav.}] \leavevmode
dla pliku ../anger/file.wav, tworzy parę {[}../anger/file.wav, anger{]}

\end{description}
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode
\sphinxstyleliteralstrong{pattern} (\sphinxstyleliteralemphasis{basestring}) \textendash{} Ścieżka do pliku z którego maja być wyodrębione pliki wav

\item[{Zwraca}] \leavevmode
list

\end{description}\end{quote}

\end{fulllineitems}

\index{connect\_to\_database() (w module helper\_file)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{helper_file:helper_file.connect_to_database}}\pysiglinewithargsret{\sphinxcode{helper\_file.}\sphinxbfcode{connect\_to\_database}}{\emph{db\_name}, \emph{db\_password}}{}
Funckja łączy się z bazą danych jako root
:param db\_name nazwa bazy danych
:type str
:param db\_password hasło do bazy danych
:type str
:return
\begin{itemize}
\item {} 
db, cursor - jeżeli połączenie zostało nawiązane

\item {} 
None, None - w przeciwnym przypadku

\end{itemize}

\end{fulllineitems}

\index{create\_summary\_table() (w module helper\_file)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{helper_file:helper_file.create_summary_table}}\pysiglinewithargsret{\sphinxcode{helper\_file.}\sphinxbfcode{create\_summary\_table}}{\emph{emotions\_list}}{}
\end{fulllineitems}

\index{euclidean\_distance() (w module helper\_file)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{helper_file:helper_file.euclidean_distance}}\pysiglinewithargsret{\sphinxcode{helper\_file.}\sphinxbfcode{euclidean\_distance}}{\emph{vec1}, \emph{vec2}}{}
Funckja oblicza dystans euklidesowy pomiędzy wektorami
:param vec1: wektor cech
:param vec2: wektor cech
:return: Dystans pomiedzy dwoma wektorami

\end{fulllineitems}

\index{get\_most\_frequently\_occurring() (w module helper\_file)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{helper_file:helper_file.get_most_frequently_occurring}}\pysiglinewithargsret{\sphinxcode{helper\_file.}\sphinxbfcode{get\_most\_frequently\_occurring}}{\emph{emotions\_set}}{}
Zwraca najczęściej występujacy element w liście
:param emotions\_set: lista elementów
:type emotions\_set: list
:return element który występuje najczęściej

\end{fulllineitems}

\index{normalize\_vector() (w module helper\_file)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{helper_file:helper_file.normalize_vector}}\pysiglinewithargsret{\sphinxcode{helper\_file.}\sphinxbfcode{normalize\_vector}}{\emph{feature\_vector}, \emph{min\_features}, \emph{max\_features}}{}
Normalizuje wektor testowy wartościami podanymi jako argumenty
:param feature\_vector: wektor cech do znormalizowania
:param min\_features: wektor najmniejszych wartości z każdej cechy, którymi należy znormalizować podany wektor
:param max\_features: wektor największych wartości z każdej cechy, którymi należy znormalizować podany wektor

\end{fulllineitems}

\index{print\_debug() (w module helper\_file)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{helper_file:helper_file.print_debug}}\pysiglinewithargsret{\sphinxcode{helper\_file.}\sphinxbfcode{print\_debug}}{\emph{text}}{}
\end{fulllineitems}

\index{print\_progress\_bar() (w module helper\_file)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{helper_file:helper_file.print_progress_bar}}\pysiglinewithargsret{\sphinxcode{helper\_file.}\sphinxbfcode{print\_progress\_bar}}{\emph{iteration}, \emph{total}, \emph{prefix=''}, \emph{suffix=''}, \emph{decimals=1}, \emph{length=100}, \emph{fill='█'}}{}
FUnckja rysuje pasek postępu
:param iteration: Obecna iteracja
:type iteration: int
:param total: Liczba wszystkich operacji
:type total: int
:param prefix: Tekst na początku paska postępu
:type prefix: str
:param suffix: Tekst na końcu paska postępu
:type suffix: str

\end{fulllineitems}

\index{print\_summary() (w module helper\_file)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{helper_file:helper_file.print_summary}}\pysiglinewithargsret{\sphinxcode{helper\_file.}\sphinxbfcode{print\_summary}}{\emph{summary\_table}, \emph{emotions\_list}}{}
function illustrating how to document python source code

\end{fulllineitems}



\section{hmm\_main module}
\label{\detokenize{hmm_main:hmm-main-module}}\label{\detokenize{hmm_main::doc}}\label{\detokenize{hmm_main:module-hmm_main}}\index{hmm\_main (moduł)}\index{hmm\_claster() (w module hmm\_main)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{hmm_main:hmm_main.hmm_claster}}\pysiglinewithargsret{\sphinxcode{hmm\_main.}\sphinxbfcode{hmm\_claster}}{\emph{feature\_vector\_set}}{}
Funkcja normalizuje i za pomocą algorytmu K-means klasteryzuje podany zestaw wektorów cech.
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode
\sphinxstyleliteralstrong{feature\_vector\_set} (\sphinxstyleliteralemphasis{list}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{vector}\sphinxstyleliteralemphasis{{]}}) \textendash{} zbiór wektoróch cech

\item[{Zwraca}] \leavevmode
\begin{itemize}
\item {} 
lista sklasteryzowancyh wektorów cech

\item {} 
wektor najmniejszych wartości z każdej cechy

\item {} 
wektor największych wartości z każdej cechy

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{hmm\_get\_all\_possible\_observations() (w module hmm\_main)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{hmm_main:hmm_main.hmm_get_all_possible_observations}}\pysiglinewithargsret{\sphinxcode{hmm\_main.}\sphinxbfcode{hmm\_get\_all\_possible\_observations}}{\emph{train\_path\_pattern}, \emph{db\_name}, \emph{db\_password}}{}
Funkcja dla każdego zestawu cech tworzy zbiór wszystkich możliwych wektorów cech, wyliczony z plików w katalogu
train\_path\_pattern, oraz klasteryzuje je w celu uzyskania ograniczonego zbioru obserwacji
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{train\_path\_pattern} (\sphinxstyleliteralemphasis{basestring}) \textendash{} ścieżka do katalogu z plikami, z których mają być wyliczone obserwacje

\item {} 
\sphinxstyleliteralstrong{db} \textendash{} baza danych do zapisu

\item {} 
\sphinxstyleliteralstrong{cursor} \textendash{} kursor na bazę danych

\item {} 
\sphinxstyleliteralstrong{summary\_table} \textendash{} tablica podsumowująca wyniki

\item {} 
\sphinxstyleliteralstrong{emotions} (\sphinxstyleliteralemphasis{list}) \textendash{} lista emocji do wykrycia

\end{itemize}

\item[{Zwraca}] \leavevmode
\begin{itemize}
\item {} 
dla każdego zestawu cech lista możliwych obserwacji

\item {} 
dla każdego zestawu cech wektor najmniejszych i największych wartości każdej z cech

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{hmm\_get\_features\_vector\_from\_dir() (w module hmm\_main)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{hmm_main:hmm_main.hmm_get_features_vector_from_dir}}\pysiglinewithargsret{\sphinxcode{hmm\_main.}\sphinxbfcode{hmm\_get\_features\_vector\_from\_dir}}{\emph{path\_pattern}}{}
Funkcja dla każdego z dla każdego zbioru cech tworzy wektor cech z plików w katalogu „path\_pattern”
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode
\sphinxstyleliteralstrong{path\_pattern} (\sphinxstyleliteralemphasis{basestring}) \textendash{} ściażka do katalogu z plikami z których należy wygenerować wektory cech

\item[{Zwraca}] \leavevmode
Dla każdego zbioru cech, lista wektorów cech

\item[{Typ zwracany}] \leavevmode
dictionary

\end{description}\end{quote}

\end{fulllineitems}

\index{hmm\_get\_features\_vectors\_from\_db() (w module hmm\_main)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{hmm_main:hmm_main.hmm_get_features_vectors_from_db}}\pysiglinewithargsret{\sphinxcode{hmm\_main.}\sphinxbfcode{hmm\_get\_features\_vectors\_from\_db}}{\emph{cursor}}{}
Funkcja dla każdego z dla każdego zbioru cech pobiera wektor cech z bazy danych, którą wskazuje cursor
\begin{quote}\begin{description}
\item[{Param}] \leavevmode
path\_pattern: kursor na bazę danych

\item[{Zwraca}] \leavevmode
Dla każdego zbioru cech, zbiór wektorów cech

\item[{Typ zwracany}] \leavevmode
dictionary

\end{description}\end{quote}

\end{fulllineitems}

\index{hmm\_get\_nearest\_neighbour() (w module hmm\_main)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{hmm_main:hmm_main.hmm_get_nearest_neighbour}}\pysiglinewithargsret{\sphinxcode{hmm\_main.}\sphinxbfcode{hmm\_get\_nearest\_neighbour}}{\emph{vec}, \emph{data}}{}
Funkcja porównuje dystans pomiędzy wektorem vec a każdym z wektórów „data”.
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{vec} (\sphinxstyleliteralemphasis{vector}) \textendash{} wektor cech

\item {} 
\sphinxstyleliteralstrong{data} (\sphinxstyleliteralemphasis{list}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{feature\_vector}\sphinxstyleliteralemphasis{{]}}) \textendash{} wszystkie akceptowalne wektory cech

\end{itemize}

\item[{Zwraca}] \leavevmode
Wektor z „data” dla którego dystans do wektora vec jest najmniejszy.

\item[{Typ zwracany}] \leavevmode
vector

\end{description}\end{quote}

\end{fulllineitems}

\index{hmm\_get\_observations\_vectors() (w module hmm\_main)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{hmm_main:hmm_main.hmm_get_observations_vectors}}\pysiglinewithargsret{\sphinxcode{hmm\_main.}\sphinxbfcode{hmm\_get\_observations\_vectors}}{\emph{file}, \emph{min\_max\_features\_vec}, \emph{all\_possible\_observations}}{}
Funkcja dla każdego zestawu cech tworzy zbiór wektorów cech wyliczonych z pliku „file”.
Każdy wektor normalizuje i przypisuje mu najbliższego sąsiada z wszystkich możliwych obserwacji.
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{file} (\sphinxstyleliteralemphasis{basestring}) \textendash{} ścieżka do pliku z którego mają być pobrane zestawy cech

\item {} 
\sphinxstyleliteralstrong{min\_max\_features} (\sphinxstyleliteralemphasis{dictionary}) \textendash{} Parametry potrzebne do normalizacji zbioru cech wektorów

\item {} 
\sphinxstyleliteralstrong{all\_possible\_observations} (\sphinxstyleliteralemphasis{vector}\sphinxstyleliteralemphasis{{[}}\sphinxstyleliteralemphasis{vector}\sphinxstyleliteralemphasis{{]}}) \textendash{} Dla każdej cechy wszystkie możliwe w HMM zbiory cech wektorów

\end{itemize}

\item[{Zwraca}] \leavevmode
Słownik zawierający dla każdego zestawu cech listę sekwencję obserwacji wygenerowanych z pliku „file”.
Każda sekwencja obserwacji jest ok 1,5sek wypowiedzią i składa się z 6 wektorów cech,
z których każdy reprezentuje 0,25s wypowiedzi.

\item[{Typ zwracany}] \leavevmode
dictionary

\end{description}\end{quote}

\end{fulllineitems}

\index{hmm\_get\_train\_set() (w module hmm\_main)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{hmm_main:hmm_main.hmm_get_train_set}}\pysiglinewithargsret{\sphinxcode{hmm\_main.}\sphinxbfcode{hmm\_get\_train\_set}}{\emph{path\_pattern}, \emph{min\_max\_features}, \emph{all\_possible\_observations}, \emph{emotions}, \emph{summary\_table}}{}
Funkcja dla każdego zestawu cech i każdej emocji tworzy zbiór sekwencji obserwacji do trenowania obiektów HMM.
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{path\_pattern} (\sphinxstyleliteralemphasis{string}) \textendash{} Ścieżka do folderu zawierające pliki dźwiękowe, z których mają być wygenerowane dane trenujące

\item {} 
\sphinxstyleliteralstrong{min\_max\_features} (\sphinxstyleliteralemphasis{dictionary}) \textendash{} Parametry potrzebne do normalizacji zbioru cech wektorów

\item {} 
\sphinxstyleliteralstrong{all\_possible\_observations} (\sphinxstyleliteralemphasis{string}) \textendash{} Wszystkie możliwe zbiory cech wektorów

\item {} 
\sphinxstyleliteralstrong{emotions} (\sphinxstyleliteralemphasis{list}) \textendash{} Lista emocji

\end{itemize}

\item[{Zwraca}] \leavevmode
Słownik, zwierający dla każdego zestawu cech i każdej emocji, listę sekwencji obserwacji (wektorów cech) z
wszystkich plików z katalogu „path\_pattern”.

\item[{Typ zwracany}] \leavevmode
dictionary

\end{description}\end{quote}

\end{fulllineitems}

\index{hmm\_main() (w module hmm\_main)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{hmm_main:hmm_main.hmm_main}}\pysiglinewithargsret{\sphinxcode{hmm\_main.}\sphinxbfcode{hmm\_main}}{\emph{train\_path\_pattern}, \emph{test\_path\_pattern}, \emph{db\_name}, \emph{db\_password}, \emph{emotions}}{}
Główna funkcja hmm. Dla każdego zestawu cech i kazdej emocji tworzy model HMM i trenuje go wektorami obserwacji
pobranymi z bazie danych db\_name jeżeli istnieją, lub w przeciwnym wypadku obliczonymi z plików znajdujacych sie w katalogu
train\_path\_pattern.

Następnie dla każdej wypowiedzi z katalogu test\_path\_pattern próbuje przewidzieć jaką emocję reprezentuje ta
wypowiedź, w następujący sposób.
Dla każdego pliku
\begin{enumerate}
\item {} 
Dla każdego zestawu cech oblicz listę sekwencji obserwacji

\item {} \begin{description}
\item[{Dla każdej sekwencji obserwacji:}] \leavevmode\begin{description}
\item[{2\_1) Dla każdej emocji oblicza prawdopodobieństwo wygenerowania sekwencji obserwacji w modelu hmm}] \leavevmode
reprezentującym emocje.

\item[{2\_2) Jako prawdopodobną emocję uznaje emocję reprezentującą przez model HMM, który zwrócił największe}] \leavevmode
prawdopodobieńśtwo wygenerowania tej sekwencji obserwacji.

\end{description}

\end{description}

\item {} 
Za emocję reprezentującą ten plik uznaje emocję, która wystąpiła największą ilosć razy

\end{enumerate}
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{train\_train\_path\_pattern} \textendash{} Ścieżka do folderu zawierające pliki dźwiękowe, z których mają
być wygenerowane dane trenujące

\item {} 
\sphinxstyleliteralstrong{test\_path\_pattern} (\sphinxstyleliteralemphasis{basestring}) \textendash{} Ścieżka do folderu zawierające pliki dźwiękowe, z których mają
być wygenerowane dane testujące

\item {} 
\sphinxstyleliteralstrong{db\_name} (\sphinxstyleliteralemphasis{basestring}) \textendash{} nazwa bazy danych

\item {} 
\sphinxstyleliteralstrong{db\_password} (\sphinxstyleliteralemphasis{basestring}) \textendash{} hasło do bazy danych

\item {} 
\sphinxstyleliteralstrong{emotions} (\sphinxstyleliteralemphasis{list}) \textendash{} zbiór emocji do rozpoznania

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{hmm\_normalize() (w module hmm\_main)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{hmm_main:hmm_main.hmm_normalize}}\pysiglinewithargsret{\sphinxcode{hmm\_main.}\sphinxbfcode{hmm\_normalize}}{\emph{feature\_vector\_set}}{}
Funkcja normalizuje podany zbiór wektorów cech
\begin{quote}\begin{description}
\item[{Param}] \leavevmode
feature\_vector\_set: Zbiór wektorów cech do znormalizowania

\item[{Type}] \leavevmode
feature\_vector\_set: list{[}vector{]}

\item[{Zwraca}] \leavevmode
\begin{itemize}
\item {} 
wektor najmniejszych wartości każdej cechy

\item {} 
wektor największych wartości każdej cechy

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}



\section{knn\_database module}
\label{\detokenize{knn_database::doc}}\label{\detokenize{knn_database:module-knn_database}}\label{\detokenize{knn_database:knn-database-module}}\index{knn\_database (moduł)}\index{is\_training\_set\_exists() (w module knn\_database)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{knn_database:knn_database.is_training_set_exists}}\pysiglinewithargsret{\sphinxcode{knn\_database.}\sphinxbfcode{is\_training\_set\_exists}}{\emph{cursor}, \emph{table}}{}
\end{fulllineitems}

\index{prepare\_db\_table() (w module knn\_database)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{knn_database:knn_database.prepare_db_table}}\pysiglinewithargsret{\sphinxcode{knn\_database.}\sphinxbfcode{prepare\_db\_table}}{\emph{db}, \emph{cursor}, \emph{table}}{}
\end{fulllineitems}

\index{save\_in\_dbtable() (w module knn\_database)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{knn_database:knn_database.save_in_dbtable}}\pysiglinewithargsret{\sphinxcode{knn\_database.}\sphinxbfcode{save\_in\_dbtable}}{\emph{db}, \emph{cursor}, \emph{vect}, \emph{tbname}}{}
\end{fulllineitems}

\index{select\_all\_from\_db() (w module knn\_database)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{knn_database:knn_database.select_all_from_db}}\pysiglinewithargsret{\sphinxcode{knn\_database.}\sphinxbfcode{select\_all\_from\_db}}{\emph{cursor}, \emph{table\_name}}{}
\end{fulllineitems}



\section{knn\_main module}
\label{\detokenize{knn_main::doc}}\label{\detokenize{knn_main:module-knn_main}}\label{\detokenize{knn_main:knn-main-module}}\index{knn\_main (moduł)}\index{knn\_compute\_emotions() (w module knn\_main)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{knn_main:knn_main.knn_compute_emotions}}\pysiglinewithargsret{\sphinxcode{knn\_main.}\sphinxbfcode{knn\_compute\_emotions}}{\emph{path\_pattern}, \emph{KNN\_modules}, \emph{summary\_table}, \emph{emotions}}{}
Funckja dla każdego pliku z path\_pattern, pobiera wektory obserwacji, a nastepnie testuje nimi
każdy z modelów KNN w celu odganięcia najbardziej prawdopodobnej emocji jaką reprezentuje plik
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{path\_pattern} (\sphinxstyleliteralemphasis{basestring}) \textendash{} ściażka do katalogu z plikami z których należy wygenerować wektory cech

\item {} 
\sphinxstyleliteralstrong{KNN\_modules} (\sphinxstyleliteralemphasis{dictionary}) \textendash{} Zbiór wytrenowanych obiektów KNN, dla każdej emocji jednej obiekt obiekt KNN

\item {} 
\sphinxstyleliteralstrong{summary\_table} (\sphinxstyleliteralemphasis{list}) \textendash{} Pomocnicza tablica do zapisywania wyników testów

\item {} 
\sphinxstyleliteralstrong{summary\_table} \textendash{} Lista emocji do przetestowania

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{knn\_get\_training\_feature\_set\_from\_db() (w module knn\_main)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{knn_main:knn_main.knn_get_training_feature_set_from_db}}\pysiglinewithargsret{\sphinxcode{knn\_main.}\sphinxbfcode{knn\_get\_training\_feature\_set\_from\_db}}{\emph{cursor}}{}
Funkcja dla każdego z dla każdego zbioru cech tworzy wektor cech z plików w katalogu „path\_pattern”
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode
\sphinxstyleliteralstrong{path\_pattern} (\sphinxstyleliteralemphasis{basestring}) \textendash{} ściażka do katalogu z plikami z których należy wygenerować wektory cech

\item[{Zwraca}] \leavevmode
Dla każdego zbioru cech lista {[}wektor cech , emocja{]}

\item[{Typ zwracany}] \leavevmode
dicttionary

\end{description}\end{quote}

\end{fulllineitems}

\index{knn\_get\_training\_feature\_set\_from\_dir() (w module knn\_main)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{knn_main:knn_main.knn_get_training_feature_set_from_dir}}\pysiglinewithargsret{\sphinxcode{knn\_main.}\sphinxbfcode{knn\_get\_training\_feature\_set\_from\_dir}}{\emph{path\_pattern}}{}
Funkcja dla każdego z dla każdego zbioru cech pobiera wektor cech oraz emocję jaką reprezentuje
z bazy danych na którą wskazuje cursor
\begin{quote}
\begin{quote}\begin{description}
\item[{param}] \leavevmode
path\_pattern: kursor na bazę danych

\item[{return}] \leavevmode
Dla każdego zbioru cech lista {[}wektor cech , emocja{]}

\item[{rtype}] \leavevmode
dictionary

\end{description}\end{quote}
\end{quote}

\end{fulllineitems}

\index{knn\_main() (w module knn\_main)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{knn_main:knn_main.knn_main}}\pysiglinewithargsret{\sphinxcode{knn\_main.}\sphinxbfcode{knn\_main}}{\emph{train\_path\_pattern}, \emph{test\_path\_pattern}, \emph{db\_name}, \emph{db\_password}, \emph{emotions}}{}
Główna funckja knn. Dla każdej emocji tworzy model KNN i trenuje go wektorami obserwacji
pobranymi z bazie danych db\_name jeżeli istnieją, lub w przeciwnym wypadku obliczonymi z plików znajdujacych sie w katalogu
train\_path\_pattern.
Następnie testuje ich działanie wektorami obserwacji obliczonymi z plików znajdujących się w test\_path\_pattern
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{train\_path\_pattern} (\sphinxstyleliteralemphasis{basestring}) \textendash{} Ścieżka do folderu zawierające pliki dźwiękowe, z których mają
być wygenerowane dane trenujące

\item {} 
\sphinxstyleliteralstrong{test\_path\_pattern} (\sphinxstyleliteralemphasis{basestring}) \textendash{} Ścieżka do folderu zawierające pliki dźwiękowe, z których mają
być wygenerowane dane testujące

\item {} 
\sphinxstyleliteralstrong{db\_name} (\sphinxstyleliteralemphasis{basestring}) \textendash{} nazwa bazy danych

\item {} 
\sphinxstyleliteralstrong{db\_password} (\sphinxstyleliteralemphasis{basestring}) \textendash{} hasło do bazy danych

\item {} 
\sphinxstyleliteralstrong{emotions} (\sphinxstyleliteralemphasis{list}) \textendash{} zbiór emocji do rozpoznania

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\section{main module}
\label{\detokenize{main:module-main}}\label{\detokenize{main::doc}}\label{\detokenize{main:main-module}}\index{main (moduł)}\phantomsection\label{\detokenize{main:module-project_documentation}}\index{project\_documentation (moduł)}\index{draw\_energy\_histogram() (w module main)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{main:main.draw_energy_histogram}}\pysiglinewithargsret{\sphinxcode{main.}\sphinxbfcode{draw\_energy\_histogram}}{}{}
\end{fulllineitems}

\index{draw\_freq\_histogram() (w module main)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{main:main.draw_freq_histogram}}\pysiglinewithargsret{\sphinxcode{main.}\sphinxbfcode{draw\_freq\_histogram}}{}{}
\end{fulllineitems}



\section{voice\_module module}
\label{\detokenize{voice_module:voice-module-module}}\label{\detokenize{voice_module::doc}}\label{\detokenize{voice_module:module-voice_module}}\index{voice\_module (moduł)}\index{get\_energy\_feature\_vector() (w module voice\_module)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{voice_module:voice_module.get_energy_feature_vector}}\pysiglinewithargsret{\sphinxcode{voice\_module.}\sphinxbfcode{get\_energy\_feature\_vector}}{\emph{sample}, \emph{window}}{}
Funkcja na podstawie podanej listy amplitude w domenie czasu oblicza wektor cech dla tych danych
:param vector sample: lista zmian energii w domenie czasu
:param window: funkcja okna
:return: lista cech na podstawie wprowadzonych danych

\end{fulllineitems}

\index{get\_feature\_vectors() (w module voice\_module)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{voice_module:voice_module.get_feature_vectors}}\pysiglinewithargsret{\sphinxcode{voice\_module.}\sphinxbfcode{get\_feature\_vectors}}{\emph{file}}{}
Funckja otwiera plik wav i dzieli go na kawałki o długości \textasciitilde{}0,25s, biorąc sample co \textasciitilde{}0,125s, czyli
kawałki nachodzą na siebie - w celu zwiększenia liczby obserwacji.
Dla każdego kawałka wypowiedzi oblicza na podstawie niego wektor cech częstotliwości i energii.
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode
\sphinxstyleliteralstrong{file} (\sphinxstyleliteralemphasis{str}) \textendash{} ścieżka do pliku z którego mają być wygenerowane wektory cech

\end{description}\end{quote}
\begin{description}
\item[{:return}] \leavevmode\begin{itemize}
\item {} 
lista wektorów cech częstotliwości

\item {} 
lista wektorów cech energii

\end{itemize}

\end{description}

\end{fulllineitems}

\index{get\_file\_info() (w module voice\_module)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{voice_module:voice_module.get_file_info}}\pysiglinewithargsret{\sphinxcode{voice\_module.}\sphinxbfcode{get\_file\_info}}{\emph{filename}}{}~\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode
\sphinxstyleliteralstrong{filename} (\sphinxstyleliteralemphasis{str}) \textendash{} Ścieżka do pliku

\item[{Zwraca}] \leavevmode
parametry pliku

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_fundamental\_freq() (w module voice\_module)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{voice_module:voice_module.get_fundamental_freq}}\pysiglinewithargsret{\sphinxcode{voice\_module.}\sphinxbfcode{get\_fundamental\_freq}}{\emph{freq\_domain\_vect}, \emph{sample\_rate}, \emph{sample\_length}}{}
Funkcja oblicza częśtotliwość bazową dla danego funkcji w domenie częsttliwości
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{freq\_domain\_vect} (\sphinxstyleliteralemphasis{vector}) \textendash{} wektor reprezentujacy funkcję w domenie częstotliowści

\item {} 
\sphinxstyleliteralstrong{sample\_rate} (\sphinxstyleliteralemphasis{int}) \textendash{} częstotliwość próbkowania dźwięku z którego pochodzi funkcja

\item {} 
\sphinxstyleliteralstrong{sample\_length} (\sphinxstyleliteralemphasis{int}) \textendash{} długosć ramki z której została wygenerowana funkcja

\end{itemize}

\item[{Return float}] \leavevmode
częstotliwość bazowa dla podanej funkcji

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_pitch\_feature\_vector() (w module voice\_module)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{voice_module:voice_module.get_pitch_feature_vector}}\pysiglinewithargsret{\sphinxcode{voice\_module.}\sphinxbfcode{get\_pitch\_feature\_vector}}{\emph{sample}, \emph{frame\_length}, \emph{window}, \emph{frame\_rate}}{}
Funkcja dla każdej rammki z sample, dłguośći frame\_length przygotowuje fft i oblicza z tego częstotliwość bazową.
Następnie tworzy listę częstotliwości bazowych i oblicza wektor cech na podsawie tych danych.
\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{sample} \textendash{} lista sampli, z ktorych ma być obliczony wetor cech częstotliwości

\item {} 
\sphinxstyleliteralstrong{frame\_length} \textendash{} Dłguosć ramki do fft

\item {} 
\sphinxstyleliteralstrong{window} \textendash{} Funkcja okna

\item {} 
\sphinxstyleliteralstrong{frame\_rate} \textendash{} Czestotliwość samplowania

\end{itemize}

\item[{Zwraca}] \leavevmode
Wektor cech częstliwośći dla podanego zbioru sampli

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_pitch\_features() (w module voice\_module)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{voice_module:voice_module.get_pitch_features}}\pysiglinewithargsret{\sphinxcode{voice\_module.}\sphinxbfcode{get\_pitch\_features}}{\emph{fundamental\_freq\_array}}{}
Funkcja na podstawie podanej listy częstotliwość bazowych oblicza wektor cech dla tych danych
:param vector fundamental\_freq\_array: wektor częstotliowści bazowych
:return: lista cech wektora

\end{fulllineitems}

\index{get\_sample\_rate() (w module voice\_module)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{voice_module:voice_module.get_sample_rate}}\pysiglinewithargsret{\sphinxcode{voice\_module.}\sphinxbfcode{get\_sample\_rate}}{\emph{filename}}{}~\begin{quote}\begin{description}
\item[{Parametry}] \leavevmode
\sphinxstyleliteralstrong{filename} (\sphinxstyleliteralemphasis{str}) \textendash{} ścieżka do pliku

\item[{Zwraca}] \leavevmode
częstotliwość samplowania

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_summary\_pitch\_feature\_vector() (w module voice\_module)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{voice_module:voice_module.get_summary_pitch_feature_vector}}\pysiglinewithargsret{\sphinxcode{voice\_module.}\sphinxbfcode{get\_summary\_pitch\_feature\_vector}}{\emph{pitch\_feature\_vectors}}{}
Funkcja na podstawie danych oblicza wektor cech częstotliwośći bazowych
:param pitch\_feature\_vectors: lista wektorów cech częstotliowśći bazowych
:return: wektor cech

\end{fulllineitems}

\index{read\_from\_wav\_file() (w module voice\_module)}

\begin{fulllineitems}
\phantomsection\label{\detokenize{voice_module:voice_module.read_from_wav_file}}\pysiglinewithargsret{\sphinxcode{voice\_module.}\sphinxbfcode{read\_from\_wav\_file}}{\emph{wav\_file}, \emph{length}}{}
Funkcja odczytuje określoną ilość próbek pochodzących z jednego chanellu z pliku wav.

:param wav\_file wskaźnik na plik wav
:param int length: liczba sampli jaką chcemy odczytać

:return {[}list{]} - lista sampli długości length, pochądzących z jednego channella.

Ponieważ rozmary sampli w pliku .wav mają różną długość należy odczytywać 1 próbkę należy odczytać określoną ilość bitów.
DO tego służy tablica ftm\_size

Sample w pliku wav są umieszczone następująco: s1\_c1, s1\_c2, s2\_c1, s2\_c2, gdzie s1 oznacza sample\_1, a c1 channel\_1.

Aby więc odczytać informację o długości n należy odczytać (fmt\_size * length * wav\_file.getnchannels()) bitów, a
następnie wziąć co x-ty element x-ty element, gdzie x to liczba channeli.

\end{fulllineitems}



\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\DUrole{xref,std,std-ref}{search}

\end{itemize}


\renewcommand{\indexname}{Indeks modułów pythona}
\begin{sphinxtheindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{h}
\item {\sphinxstyleindexentry{hanning\_window}}\sphinxstyleindexpageref{hanning_window:\detokenize{module-hanning_window}}
\item {\sphinxstyleindexentry{helper\_file}}\sphinxstyleindexpageref{helper_file:\detokenize{module-helper_file}}
\item {\sphinxstyleindexentry{HMM}}\sphinxstyleindexpageref{HMM:\detokenize{module-HMM}}
\item {\sphinxstyleindexentry{hmm\_main}}\sphinxstyleindexpageref{hmm_main:\detokenize{module-hmm_main}}
\indexspace
\bigletter{k}
\item {\sphinxstyleindexentry{KNN}}\sphinxstyleindexpageref{KNN:\detokenize{module-KNN}}
\item {\sphinxstyleindexentry{knn\_database}}\sphinxstyleindexpageref{knn_database:\detokenize{module-knn_database}}
\item {\sphinxstyleindexentry{knn\_main}}\sphinxstyleindexpageref{knn_main:\detokenize{module-knn_main}}
\indexspace
\bigletter{m}
\item {\sphinxstyleindexentry{main}}\sphinxstyleindexpageref{main:\detokenize{module-main}}
\indexspace
\bigletter{p}
\item {\sphinxstyleindexentry{project\_documentation}}\sphinxstyleindexextra{OS X}\sphinxstyleindexpageref{main:\detokenize{module-project_documentation}}
\indexspace
\bigletter{v}
\item {\sphinxstyleindexentry{voice\_module}}\sphinxstyleindexpageref{voice_module:\detokenize{module-voice_module}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Indeks}
\printindex
\end{document}